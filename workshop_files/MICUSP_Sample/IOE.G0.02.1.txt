The design features of a speedometer are not trivial details. Everyday, millions of people rely on speedometer details when driving automobiles. A few small defects in the speedometer design could distract the driver enough time to cause an accident and potentially cost many people their lives. Consequently, studying the effects of speedometer design parameters on speedometer reading time and accuracy is very important. The design parameters examined in the experiment include character color, location on the instrument panel, character size (strokewidth and height), radius and numbering scale. Each parameter was examined in order to explore the possible combinations of design features such that the speedometer average reading time would be low as well as having high reading accuracy. These design parameters, however, may have a different effect on reading time and accuracy depending on the task condition. Two task conditions were examined in this experiment. The first speedometer task condition was to find the exact speed while the second was to verify if the vehicle was above or below the speed limit. Therefore, the two objectives of the experiment were.
-To find the relationship between speedometer design parameters, task condition and task performance (reading time and accuracy).
-To find which speedometer is best for each given task condition and why.
The experiment was conducted using 13 test participants. Appendix A displays the relevant information for each test participant. All the test subjects were volunteers and students of the University of Michigan. There were many individual differences between the test participants that were considered relevant to the experiment and will be analyzed in later sections of this report. These differences include participant vision, handedness, sex and viewing distance. All other factors were considered negligible. For example, test participant age was considered to be negligible due to the small range of values (18 to 21).
The experiment used a simple projection and timing system to collect the data. This system included the following equipment.
The DRCU, PSCU, and response boxes were all custom made at the University of Michigan. This system worked such that the software in the computer controlled, directly or indirectly, all the elements of the system. The software was called RT334 and written by Prof. Chuck Wooley of the University of Michigan. The system projected various images of speedometers for an exact determined amount of time while being able to store data that was collected at the response boxes. The images were projected on a large projection screen in the front of the room. Two TVs were used to show summary data to the test participants in between testing blocks. Figure 1 displays the system's electronic connections.
Figure 1. Projection and Timing System Electronic Connections
Figure 1 displays how the computer, directly or indirectly, controlled the entire system.
Four unique speedometers were used in the experiment. Table gives a description of the significant differences for each speedometer. It is important to note that the measurement values are for the size of the characteristics when projected on the screen, not the actual size.
Table 1. Speedometer Characteristics and Attributes
One characteristic of speedometer 4 that is not apparent from Table 1 is that the first number on the speedometer after 0 mph was 15 mph. From then on a scale of 10 mph was used. All the speedometers were circular in shape. The pointing needles of the different speedometers had negligible differences. Figure 2 displays the instrument control panel layout, common to all the speedometers, shown on the projection screen (without negligible and non-effecting details).
Figure 2. Common Instrument Control Panel Layout (not to scale)
The speedometer was found in either of the large, inner circles in Figure 1. The other circles represent other gauges for RPM, temperature, oil level, etc. Other test materials and equipment used in the experiment include a standard tape measure, chairs, and tables.
Each experiment began with the 13 test participants seated in two rows, each with their own response pad directly in front of them on a standard classroom table. The middle of the first row was 10 feet and 5 inches from the projection screen and had 8 participants. The second row, containing 5 participants, was 15 feet from the projection screen. The participants in the second row were sitting in slightly higher (approx. 6 inches) chairs than the first row. Figure 3 depicts the testing room layout.
Figure 3. Testing Room Layout
Each number on figure 3 represents the respective test participant's seat. Both televisions projected identical information, which was easily visible for every test participant.
The experiment was run in blocks of trials. Each trial began when the shutter opened revealing an image of a speedometer. This is also when the clock started for the trial. The participants could then begin to enter a response by pushing a button on the response box in front of them. After pushing the button, a signal would be sent indirectly to the computer. The time after the shutter opened until the response button was pushed was stored in the computer for each participant. The shutter would then close, completing the exposure duration. The participant could enter a response after the shutter closed, but only until the maximum response time for that trial. Only the first response the test participant gave was recorded. If the participant had responded with an incorrect response (error), the time as well as the fact that it was incorrect was recorded. After the maximum response time, data collection ended and the projector advanced. If the participant gave no response, the maximum response time was recorded for that participant as well as the fact that the participant did not respond (miss). The time in between the end of data collection and the shutter opening again was called the intertrial interval and was common for all trials.
Nine blocks, each with either 16 or 32 trials were conducted. In all the blocks the speedometers read 50, 55, 60 or 65 mph. With blocks 1 through 6, each participant pressed one of the four buttons on the response box that had been assigned a respective speedometer reading (50, 55, 60 or 65 mph). In blocks 7 through 9, the participants pressed 1 of the 2 buttons that had been assigned "speeding" and "not speeding" . The "speed limit" was considered to be 55 mph. In both protocols, the participants were instructed to assign one finger for each button. Also, before every block the test participants were given the instruction to "be as fast and as accurate as possible" . The first two blocks were practice in order to familiarize the test participants with the routine and system. Block 7 was also practice because of the new response protocol. The practice blocks had one large difference from the testing blocks. In the practice blocks no speedometers were shown, only 3 boxes, each with a word in them. Only one box actually had a correct spelling of fifty, fifty-five, sixty or sixty-five. The one correctly spelled speed was viewed as the speedometer reading for the trial. This difference was to make sure that the test participants did not get any practice at looking at any speedometer before they were tested on it. Also, between each block, the test participants were shown their mean response time and error count of the previous block on the 2 televisions in the front of the room.
The speedometers were grouped into 2 groups. Speedometers 1 and 2 were group A and speedometers 3 and 4 were group B. Only one group was shown per block of trials. Within each block, the 2 speedometers of the group as well as the reading on them would randomly change from trial to trial. Table 2 displays each block with its respective parameters.
Table 2. Individual Block Descriptions
* The first trial of block 5 had an error and was considered junk. This means that there were only 31 legitimate trials in block 5.
The first step in analyzing the data was look at the summary data of each block with respect to each speedometer. Table 3 displays each speedometer's average response time for each block in which the speedometer was shown.
Table 3. Average Response Time (s) for Each Speedometer in Each Block
Table 4 displays the average error percentage rate and average miss percentage rate for each speedometer.
Table 4. Average Error and Miss Percentage Rates
Comparing blocks 3 and 5 (the blocks with prolonged speedometer exposure duration), patterns become apparent. Speedometer 2 had the lowest average response time and the lowest error and miss percentage rates. Speedometer 1 was very close in average response time, but not as close in error rate. Speedometers 3 and 4 seem to be stratified from speedometers 1 and 2 in response time. One possible explanation for these differences can be in the overall size of speedometers 1 and 2 versus 3 and 4. Speedometer set A averaged much larger character strokewidth, character height, and speedometer radius than speedometer set B, accounting for the large difference in task performances.
Comparing blocks 4 and 6 (the blocks with shortened speedometer exposure duration), similar patterns become apparent. Overall, the average response times were all reduced from blocks 3 and 5. Also, as with blocks 3 and 5, speedometer set A is stratified from speedometer set B in that it has much lower average response times. Overall, average error and miss percentage rates were much higher than in blocks 3 and 5 due to the shortened exposure time for the blocks. This shows that as response time decreased, error and miss percentage rate increased. The error rates for all the speedometers were about equal, however, the average miss percentage rates for set B were double that of set A. This can also be attributed to the overall size difference of the speedometer parameters.
When the task condition changed to whether or not the car was "speeding" , the patterns remained the same. Speedometer set A had lower average response times than set B, as well as having lower average error rate percentages. Overall speedometer response times as well as error and miss percentage rates did decrease due to the lower number of response choices.
The overall size increase of many speedometer design parameters between speedometer set A to set B seem to have accounted for the overall lower average response times and lower average error and miss percentage rates. However, other design differences, such as location of the speedometer on the instrument display panel, did not have such influential effects on the data. Comparing speedometers 1 and 4 (speedometer on left side) to speedometers 2 and 3 (speedometer on right side) only one small pattern was seen. Speedometers 2 and 3 had, compared to their respective speedometer set, slightly lower average response times than the other speedometer in the set. Whether or not this small difference in average response time can be attributed to the location of the speedometers on the instrument display panel was not possible.
Other major differences in design features within speedometer set B also seemed to have little effect on the data. Speedometer 4 had a different character color, location, numbering scale and character height than speedometer 3. However, the differences did not produce much stratification in the data. Speedometer 4 had slightly lower average error and miss percentage rates than speedometer 3 while speedometer 3 had slightly lower average response times than speedometer 4. From prior established patterns, the speedometer with larger character height (speedometer 4 in this case) should have had lower average response times and error and miss percentage rates. Although speedometer 4 did have lower error and miss percentage rates, it did not have lower average response times. Therefore, it is possible that the combined differences in speedometer design between speedometers 3 and 4 caused speedometer 4 to be slightly less legible than speedometer 3.
Speedometers 1 and 2 differed in location and radius size. However, the speedometers differed only slightly in average response times and error and miss percentage rates. Speedometer 2 consistently had the lowest average response time as well as having the lower average error and miss percentage rates (except in one instance). The effect of location, as discussed earlier, was not clear. However, the larger radius of speedometer 2 could of caused the small differences in the data. This inference continues the pattern concerning the size of speedometer parameters.
It is necessary to examine the effects of the test participant differences in order to find any discrepancies in the data. The relevant differences examined were sex, handedness, visibility (defined as the need of correctional lenses vs. no need), and distance from the projection screen. The first step in evaluating the effect of the test participant differences was to compare how each of the 4 modeled differences affected the average response times and total incorrect (errors and misses) responses. The discrepancies in average response times for most of the test participant differences were very small (less than 0.060 s). The same result occurred for the average incorrect responses. The sample size of test participants was also small, making almost all inferences impossible. However, the one individual difference that did stick out as possibly meaningful was sex. The average response times for males were, on average, 0.111 s faster than for females. Also, the average total incorrect responses for the males was 6.3 less than for females. One explanation for this difference can be attributed to the test sequence. Due to the 2 televisions, all the participants could see each other's average response times after every block, creating a small competition in which males are commonly known to be more aggressive and competitive. This would explain the reason for the 0.111 s lower male average response time.
In order to find the best speedometer of the 4 examined, it is required to first define which task condition is being used. For the task condition of reading the exact speed (4 choices), speedometer 2 was clearly the optimal speedometer. It consistently had the lowest average response time and average miss percentage rate. It had the lowest average error rate percentage one of the two 4 choice blocks.
For the task condition of "speeding" versus "non-speeding" (2 choices), the decision was not as simple. Although speedometer 2 had the lowest average response time, it had 6 errors. Speedometer 1 had a slightly larger average response time with 4 errors. However, the task performance measurement that becomes more important in the selection criteria for this task condition should be the average response time. This is because the most important task while driving is to have your eyes on the road. Whether you are mistaken in your knowledge of speeding or not speeding is generally not as important to your safety as the time you look away from the road. Therefore, the optimal speedometer for this task condition was also speedometer 2.
The relationships between speedometer design parameters, task condition and task performance were not obvious or clear given the collected data. However, some inferences can be drawn. For example, the larger the character height, character strokewidth and radius, no matter what the task condition, the more the task performance improved. This was shown in the stratification between speedometer sets A and B for all task conditions in the task performance measurements. This pattern was also visible when speedometers 1 and 2 were compared based on their radius size. Conclusions about the effects of location, character color and numbering scale were not possible.
Using the relationships found above as well as the data collected, the optimal speedometers for each task condition were found. Using low response time and incorrect response rate as the criteria, speedometer 2 was selected the optimal speedometer for both task conditions. One interesting point was the difference in importance between response time and incorrect response rate. This was concluded due to the natural consequence of not having your eyes on the road. The safety issues concerning the amount of time your eyes are off the road are generally more severe than incorrect knowledge of whether you are speeding.
Revisions in the experiment could prove to be very helpful. For example, due to the poor choice of speedometers, it was very difficult to assign the causes of differences in task performance to attributes of the speedometers. Speedometers with similar characteristics and one large difference should have been chosen for the experiment such that the process of assigning the causes of differences in the data could have been clearer. Also, a larger sample size of test participants as well as testing blocks should have been used to increase confidence in the inferences made. With these changes, the experiment could be much more effective in answering the objectives stated.